{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 9.]\n",
      " [1. 5.]\n",
      " [3. 6.]]\n",
      "[[92.]\n",
      " [86.]\n",
      " [89.]]\n",
      "[[0.06993189 0.81053904 0.91735321]\n",
      " [0.22411612 0.61548841 0.80166258]]\n",
      "[[0.59520159]\n",
      " [0.33653677]\n",
      " [0.54714391]]\n",
      "Predicted output\n",
      "[[80.4842858 ]\n",
      " [79.07417234]\n",
      " [79.80316274]]\n",
      "Actual Output \n",
      "[[92.]\n",
      " [86.]\n",
      " [89.]]\n"
     ]
    }
   ],
   "source": [
    "     import numpy as np\n",
    "X= np.array(([2,9],[1,5],[3,6]), dtype=float)\n",
    "y= np.array(([92],[86],[89]), dtype=float)\n",
    "print(X)\n",
    "print(y)\n",
    "    #x=X.np.amax(X,axis=0)\n",
    "    #y=y/100;      #max marks in 100\n",
    "\n",
    "class Neural_Network(object):\n",
    "        def __init__(self):\n",
    "            self.inputsize=2\n",
    "            self.outputsize=1\n",
    "            self.hiddensize=3\n",
    "            self.W1=np.random.rand(self.inputsize,self.hiddensize)\n",
    "            self.W2=np.random.rand(self.hiddensize,self.outputsize)\n",
    "            print(self.W1) \n",
    "            print(self.W2)\n",
    "            \n",
    "        def forward(self,X):\n",
    "         #forward propagation\n",
    "            self.z=np.dot(X,self.W1)\n",
    "            self.z1=self.sigmoid(self.z)\n",
    "            self.z2=np.dot(self.z1,self.W2)\n",
    "            o=self.sigmoid(self.z2)\n",
    "            return o*100    #had to multiply by 100\n",
    "\n",
    "        def sigmoid(self,s):\n",
    "            return 1/(1+np.exp(-s))\n",
    "\n",
    "        \n",
    "NN=Neural_Network()\n",
    "o=NN.forward(X)\n",
    "\n",
    "print(\"Predicted output\\n\" +str(o))\n",
    "print(\"Actual Output \\n\" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "[[2. 9.]\n",
      " [1. 5.]\n",
      " [3. 6.]]\n",
      "Actual Output: \n",
      "[[92.]\n",
      " [86.]\n",
      " [89.]]\n",
      "Predicted Output: \n",
      "[[0.86687417]\n",
      " [0.86413018]\n",
      " [0.86651563]]\n",
      "Loss: \n",
      "11.303093078696579\n",
      "\n",
      "\n",
      "\n",
      "train\n",
      "[[2. 9.]\n",
      " [1. 5.]\n",
      " [3. 6.]]\n",
      "[[0.86687417]\n",
      " [0.86413018]\n",
      " [0.86651563]]\n",
      "inside backward\n",
      "Input: \n",
      "[[2. 9.]\n",
      " [1. 5.]\n",
      " [3. 6.]]\n",
      "Actual Output: \n",
      "[[92.]\n",
      " [86.]\n",
      " [89.]]\n",
      "Predicted Output: \n",
      "[[0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "Loss: \n",
      "1527.0\n",
      "\n",
      "\n",
      "\n",
      "train\n",
      "[[2. 9.]\n",
      " [1. 5.]\n",
      " [3. 6.]]\n",
      "[[0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "inside backward\n"
     ]
    }
   ],
   "source": [
    "     import numpy as np\n",
    "X= np.array(([2,9],[1,5],[3,6]), dtype=float)\n",
    "y= np.array(([92],[86],[89]), dtype=float)\n",
    "#print(X)\n",
    "#print(Y)\n",
    "    #x=X.np.amax(X,axis=0)\n",
    "    #y=y/100;      #max marks in 100\n",
    "\n",
    "class Neural_Network(object):\n",
    "        def __init__(self):\n",
    "            self.inputsize=2\n",
    "            self.outputsize=1\n",
    "            self.hiddensize=3\n",
    "            self.W1=np.random.rand(self.inputsize,self.hiddensize)\n",
    "            self.W2=np.random.rand(self.hiddensize,self.outputsize)\n",
    "            #print(self.W1) \n",
    "            #print(self.W2)\n",
    "            \n",
    "        def forward(self,X):\n",
    "         #forward propagation\n",
    "            self.z=np.dot(X,self.W1)\n",
    "            self.z1=self.sigmoid(self.z)\n",
    "            self.z2=np.dot(self.z1,self.W2)\n",
    "            o=self.sigmoid(self.z2)\n",
    "            return o\n",
    "\n",
    "        def sigmoid(self,s):\n",
    "            return 1/(1+np.exp(-s))\n",
    "\n",
    "        \n",
    "        def sigmoidprime(self,s):\n",
    "            return s*(1-s)\n",
    "\n",
    "        def backward(self,X,y,o):\n",
    "            print(\"inside backward\")\n",
    "            self.o_error=y-o;\n",
    "            self.o_delta=self.o_error*self.sigmoidprime(o)\n",
    "    \n",
    "            self.z2_error=self.o_delta.dot(self.W2.T)\n",
    "            self.z2_delta=self.z2_error*self.sigmoidprime(self.z2)\n",
    "    \n",
    "            self.W1+=X.T.dot(self.z2_delta)   #input to hidden weights\n",
    "            self.W2+=self.z2.T.dot(self.o_delta)  # hidden to output weights  \n",
    "    \n",
    "        def train(self,X,y):\n",
    "            print('\\ntrain')\n",
    "            print(str(X))\n",
    "            print(str(o))\n",
    "            self.backward(X,y,o)\n",
    "    \n",
    "NN = Neural_Network()\n",
    "for i in range(2): \n",
    "    print (\"Input: \\n\" + str(X) )\n",
    "    print (\"Actual Output: \\n\" + str(y))\n",
    "    o=NN.forward(X)\n",
    "    print (\"Predicted Output: \\n\" + str(o)) \n",
    "    print (\"Loss: \\n\" + str(np.mean(np.square(y - 100*NN.forward(X))))) # mean sum squared loss\n",
    "    print (\"\\n\")\n",
    "    NN.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "[[2. 9.]\n",
      " [1. 5.]\n",
      " [3. 6.]]\n",
      "Actual Output: \n",
      "[[92.]\n",
      " [86.]\n",
      " [89.]]\n",
      "Predicted Output: \n",
      "[[0.85664806]\n",
      " [0.83115426]\n",
      " [0.85613813]]\n",
      "Loss: \n",
      "19.973905323036814\n",
      "\n",
      "\n",
      "\n",
      "train\n",
      "inside backward\n",
      "o_error[[6.3351942 ]\n",
      " [2.88457411]\n",
      " [3.38618702]]\n",
      "o_delta[[0.77797555]\n",
      " [0.40481206]\n",
      " [0.41706187]]\n",
      "z error[[0.42630284 0.41491967 0.61622314]\n",
      " [0.22182257 0.21589944 0.32064576]\n",
      " [0.22853502 0.22243266 0.33034865]]\n",
      "z d error[[-0.60033424 -0.58430407 -0.86778651]\n",
      " [-0.20994703 -0.20434101 -0.30347961]\n",
      " [-0.31939433 -0.31086584 -0.46168629]]\n",
      "weights before[[0.99897164 0.27406229 0.60698806]\n",
      " [0.08273869 0.20248482 0.39069179]]\n",
      "[[0.54796432]\n",
      " [0.53333253]\n",
      " [0.79208549]]\n",
      "weights after[[ -1.36982688  -2.03148437  -2.81712344]\n",
      " [ -8.28637068  -7.94315189 -11.70690259]]\n",
      "[[3.3278342 ]\n",
      " [3.31320241]\n",
      " [3.57195537]]\n",
      "Input: \n",
      "[[2. 9.]\n",
      " [1. 5.]\n",
      " [3. 6.]]\n",
      "Actual Output: \n",
      "[[92.]\n",
      " [86.]\n",
      " [89.]]\n",
      "Predicted Output: \n",
      "[[0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "Loss: \n",
      "1527.0\n",
      "\n",
      "\n",
      "\n",
      "train\n",
      "inside backward\n",
      "o_error[[42.]\n",
      " [36.]\n",
      " [39.]]\n",
      "o_delta[[10.5 ]\n",
      " [ 9.  ]\n",
      " [ 9.75]]\n",
      "z error[[34.94225913 34.78862535 37.5055314 ]\n",
      " [29.95050783 29.81882173 32.14759834]\n",
      " [32.44638348 32.30372354 34.82656487]]\n",
      "z d error[[2.09380129e-31 2.08459528e-31 2.24739704e-31]\n",
      " [9.91664798e-17 9.87304656e-17 1.06441072e-16]\n",
      " [9.39148372e-22 9.35019133e-22 1.00804183e-21]]\n",
      "weights before[[ -1.36982688  -2.03148437  -2.81712344]\n",
      " [ -8.28637068  -7.94315189 -11.70690259]]\n",
      "[[3.3278342 ]\n",
      " [3.31320241]\n",
      " [3.57195537]]\n",
      "weights after[[ -1.36982688  -2.03148437  -2.81712344]\n",
      " [ -8.28637068  -7.94315189 -11.70690259]]\n",
      "[[3.3278342 ]\n",
      " [3.31320241]\n",
      " [3.57195537]]\n"
     ]
    }
   ],
   "source": [
    "     import numpy as np\n",
    "X= np.array(([2,9],[1,5],[3,6]), dtype=float)\n",
    "y= np.array(([92],[86],[89]), dtype=float)\n",
    "#print(X)\n",
    "#print(Y)\n",
    "    #x=X.np.amax(X,axis=0)\n",
    "    #y=y/100;      #max marks in 100\n",
    "\n",
    "class Neural_Network(object):\n",
    "        def __init__(self):\n",
    "            self.inputsize=2\n",
    "            self.outputsize=1\n",
    "            self.hiddensize=3\n",
    "            self.W1=np.random.rand(self.inputsize,self.hiddensize)\n",
    "            self.W2=np.random.rand(self.hiddensize,self.outputsize)\n",
    "            #print(self.W1) \n",
    "            #print(self.W2)\n",
    "            \n",
    "        def forward(self,X):\n",
    "         #forward propagation\n",
    "            self.z=np.dot(X,self.W1)\n",
    "            self.z1=self.sigmoid(self.z)\n",
    "            self.z2=np.dot(self.z1,self.W2)\n",
    "            o=self.sigmoid(self.z2)\n",
    "            return o\n",
    "\n",
    "        def sigmoid(self,s):\n",
    "            return 1/(1+np.exp(-s))\n",
    "\n",
    "        \n",
    "        def sigmoidprime(self,s):\n",
    "            return s*(1-s)\n",
    "\n",
    "        def backward(self,X,y,o):\n",
    "            print(\"inside backward\")\n",
    "            #print(str(o))\n",
    "            self.o_error=y-o*100;\n",
    "            print('o_error'+str(self.o_error))\n",
    "            self.o_delta=self.o_error*self.sigmoidprime(o)\n",
    "            print('o_delta'+str(self.o_delta))\n",
    "            self.z2_error=self.o_delta.dot(self.W2.T)\n",
    "            self.z2_delta=self.z2_error*self.sigmoidprime(self.z2)\n",
    "            print('z error' +str(self.z2_error))\n",
    "            print('z d error' +str(self.z2_delta))\n",
    "            print('weights before'+str(self.W1))\n",
    "            print(str(self.W2))\n",
    "            self.W1+=X.T.dot(self.z2_delta)   #input to hidden weights\n",
    "            self.W2+=self.z2.T.dot(self.o_delta)  # hidden to output weights  \n",
    "            print('weights after'+str(self.W1))\n",
    "            print(str(self.W2))\n",
    "            \n",
    "    \n",
    "        def train(self,X,y):\n",
    "            print('\\ntrain')\n",
    "            #print(str(X))\n",
    "            o=self.forward(X)\n",
    "           # print(str(o))\n",
    "            self.backward(X,y,o)\n",
    "    \n",
    "NN = Neural_Network()\n",
    "for i in range(2): # trains the NN 1,000 times\n",
    "    print (\"Input: \\n\" + str(X) )\n",
    "    print (\"Actual Output: \\n\" + str(y))\n",
    "    print (\"Predicted Output: \\n\" + str((NN.forward(X)))) \n",
    "    print (\"Loss: \\n\" + str(np.mean(np.square(y - 100*NN.forward(X))))) # mean sum squared loss\n",
    "    print (\"\\n\")\n",
    "    NN.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
